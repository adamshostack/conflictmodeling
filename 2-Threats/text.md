# Text and Words: The Pen Is Mightier Than The Sword
Words can be used for nearly any purpose, and considering the ways in which they can be used to hurt seems a nearly endless process.  Words can either carry hurtful meanings ("You should be killed") or harmful content ("evil.org/infectme.html", "malware.zip").

* Imitation/impersonation
* Confusion including misleading news articles
* Deception
* Overwhelming
* Cheating
* Abuse
* Threats
* Harassment
* Message deletion by senders (unsend, recall can be [used](https://www.abc.net.au/triplej/programs/hack/bumble-changes-unmatch-function-hack-four-corners/12873516) by a perpetrator.)

## Misinformation/Disinformation
A taxonomy of mis- and disinformation:

* Fabricated content
* Manipulated content
* Imposter content
* False content
* Misleading content
* False connection
* Satire or parody

## AI Driven text
Quantity has its own qualities.  Being able to scale to a very high volume of fake text can enable an attacker to overwhelm a discussion, drive out human conversation with either spam or apparently relevant content. In combination with fake accounts, it can tap into mechanisms like social proof, and make it appear that many people hold the view that the AI is espousing.  Even with a single account, it can generate so much text that it's impossible for a person to parse or respond to it all.  This can be a [Gish Gallop](https://en.wikipedia.org/wiki/Gish_gallop) on steroids.

In their [release of the GPT-2 language module](https://blog.openai.com/better-language-models/) the OpenAI institute flags the following issues:
* Generate misleading news articles
* Impersonate others online
* Automate the production of abusive or faked content to post on social media
* Automate the production of spam/phishing content
(Also, note that sample 8 uses logic very similar to sophisticated fake news postings, drawing on skepticism, critical thinking, and new approaches to a complex problem.  And was generated by an AI)
