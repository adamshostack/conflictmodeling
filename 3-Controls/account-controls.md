# Account Controls

## Account Review
Account review is a blanket term for human decision making when an account is flagged.  Review systems are controversial because they can appear arbitrary, they often involve reduced access, and they don't always result in the decision that a reporter wants. 

Decisions to be made include:
1. Triggers Flagging can happen because of customer complaints, government actions or internal systems such as ML raising concerns.
2. Review process.  What is done by whom, how quickly?  What are the right metrics for the reviewers?
3. Transparency. How much of what happens in review is specified for the public?  More transparency may lead to gaming; less leads to confusion, accusations of Kafka-esque process.
4. Appeals. What's the normal process? What's the escalation process when a very public account gets flagged (eg, President Trump violating Twitter rules regarding threats?)


## Know your customer/user
For promoted/paid content (such as adverts) there can be an identification/validation (This is sold as "ID&V") process and at the very least before the automation of putting out paid content. 

Challenges include
* Automated systems are easily subverted.  Consider a malware distributor setting up "People for Doing the Right Thing, LLC."
* A single peice of content can be amplified by casaciding user sharing. 
* Users should also have visibility on who is paying for the advert.

## Limit Automation by default
Many platforms provide APIs for automation. One way to limit abuse of these APIS is to provide limited capabilities an unlock them after verification, time on platform, time using the platform without complaint.  This is of limited help after account takeover.

## Limit 2nd degree data harvesting
In complex privacy models there are challenges when a user consents to provide personal data to a known colleague/other user and that person has is data harvested by an app, which icludes the other user. The platform should allow limitiations to limit such data mining sprawls.



